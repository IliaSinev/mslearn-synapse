{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Creating a Classification Model\n",
        "\n",
        "In this exercise, you will implement a classification model that uses features of a flight to predict whether or not it will be late.\n",
        "\n",
        "## Import Spark SQL and Spark MLlib Libraries\n",
        "\n",
        "First, import the libraries you will need to train the model:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.feature import VectorAssembler, StringIndexer, MinMaxScaler\n",
        "\n",
        "filestore = \"abfss://files@datalakeXXXXXXX.dfs.core.windows.net\"\n",
        "\n",
        "print(\"Libraries imported!\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Source Data\n",
        "The data for this exercise is provided as a CSV file containing details of flights that has already been cleaned up for modeling. The data includes specific characteristics (or *features*) for each flight, as well as a *label* column indicating whether or not the flight was late (a flight with an arrival delay of more than 25 minutes is considered *late*).\n",
        "\n",
        "You will load this data into a dataframe and display it."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "flightSchema = StructType([\n",
        "  StructField(\"DayofMonth\", IntegerType(), False),\n",
        "  StructField(\"DayOfWeek\", IntegerType(), False),\n",
        "  StructField(\"Carrier\", StringType(), False),\n",
        "  StructField(\"OriginAirportID\", IntegerType(), False),\n",
        "  StructField(\"DestAirportID\", IntegerType(), False),\n",
        "  StructField(\"DepDelay\", IntegerType(), False),\n",
        "  StructField(\"ArrDelay\", IntegerType(), False),\n",
        "  StructField(\"Late\", IntegerType(), False),\n",
        "])\n",
        "\n",
        "data = spark.read.csv(filestore + '/data/flights.csv', schema=flightSchema, header=True)\n",
        "display(data.limit(20))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "scrolled": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split the Data\n",
        "It is common practice when building supervised machine learning models to split the source data, using some of it to train the model and reserving some to test the trained model. In this exercise, you will use 70% of the data for training, and reserve 30% for testing."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "splits = data.randomSplit([0.7, 0.3])\n",
        "train = splits[0]\n",
        "test = splits[1]\n",
        "train_rows = train.count()\n",
        "test_rows = test.count()\n",
        "print (\"Training Rows:\", train_rows, \" Testing Rows:\", test_rows)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare the Training Data\n",
        "\n",
        "A predictive model often requires multiple stages of feature preparation. For example, it is common when using some algorithms to distingish between continuous features (which have a calculable numeric value) and categorical features (which are numeric representations of discrete categories). It is also common to *normalize* continuous numeric features to use a common scale - for example, by scaling all numbers to a proportional decimal value between 0 and 1 (strictly speaking, it only really makes sense to do this when you have multiple numeric columns - normalizing them all to similar scales prevents a feature with particularly large values from dominating the training of the model - in this case, we only have one non-categorical numeric feature; but we've included this so you can see how it's done!).\n",
        "\n",
        "A pipeline consists of a series of *transformer* and *estimator* components that typically prepare a dataframe for\n",
        "modeling and then train a predictive model. In this case, you will create a pipeline with the following components:\n",
        "- A **StringIndexer** estimator for each categorical variable to generate numeric indexes for categorical features\n",
        "- A **VectorAssembler** that creates a vector of continuous numeric features\n",
        "- A **MinMaxScaler** that normalizes vector of numeric features\n",
        "- A **VectorAssembler** that creates a vector of categorical and continuous features\n",
        "- A **LogisticRegression** algorithm that trains a classification model.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "## Need all types to be the same?\n",
        "\n",
        "monthdayIndexer = StringIndexer(inputCol=\"DayofMonth\", outputCol=\"DayofMonthIdx\")\n",
        "weekdayIndexer = StringIndexer(inputCol=\"DayOfWeek\", outputCol=\"DayOfWeekIdx\")\n",
        "carrierIndexer = StringIndexer(inputCol=\"Carrier\", outputCol=\"CarrierIdx\")\n",
        "originIndexer = StringIndexer(inputCol=\"OriginAirportID\", outputCol=\"OriginAirportIdx\")\n",
        "destIndexer = StringIndexer(inputCol=\"DestAirportID\", outputCol=\"DestAirportIdx\")\n",
        "numVect = VectorAssembler(inputCols = [\"DepDelay\"], outputCol=\"numFeatures\")\n",
        "minMax = MinMaxScaler(inputCol = numVect.getOutputCol(), outputCol=\"normNums\")\n",
        "featVect = VectorAssembler(inputCols=[\"DayofMonthIdx\", \"DayOfWeekIdx\", \"CarrierIdx\", \"OriginAirportIdx\", \"DestAirportIdx\", \"normNums\"], outputCol=\"features\")\n",
        "lr = LogisticRegression(labelCol=\"Late\", featuresCol=\"features\")\n",
        "pipeline = Pipeline(stages=[monthdayIndexer, weekdayIndexer, carrierIndexer, originIndexer, destIndexer, numVect, minMax, featVect, lr])\n",
        "print (\"Pipeline defined!\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "scrolled": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train a Classification Model\n",
        "\n",
        "The pipeline itself is an estimator, and so it has a **fit** method that you can call to run the pipeline on a specified dataframe. In this case, you will run the pipeline on the training data to train a model."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "model = pipeline.fit(train)\n",
        "print (\"Model trained!\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "scrolled": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test the Model\n",
        "Now you're ready to use the **transform** method of the model to generate some predictions. You can use this approach to predict delay status for flights where the label is unknown; but in this case you are using the test data which includes a known true label value, so you can compare the predicted status to the actual status."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = model.transform(test)\n",
        "predicted = prediction.select(\"features\", \"probability\", col(\"prediction\").cast(\"Int\"), col(\"Late\").alias(\"trueLabel\"))\n",
        "display(predicted.limit(100))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "scrolled": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking at the result, the **prediction** column contains the predicted value for the label, and the **trueLabel** column contains the actual known value from the testing data. The **probability** column shows the probability score for each class (0 or 1). It looks like there are a mix of correct and incorrect predictions, and the ones that are incorrect tend to have fairly close probabilities for each class. Later in this course you'll learn how to measure the accuracy of a model."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compute Confusion Matrix Metrics\r\n",
        "Classifiers are typically evaluated by creating a *confusion matrix*, which indicates the number of:\r\n",
        "- True Positives\r\n",
        "- True Negatives\r\n",
        "- False Positives\r\n",
        "- False Negatives\r\n",
        "\r\n",
        "From these core measures, other evaluation metrics such as *precision* and *recall* can be calculated."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tp = float(predicted.filter(\"prediction == 1.0 AND truelabel == 1\").count())\r\n",
        "fp = float(predicted.filter(\"prediction == 1.0 AND truelabel == 0\").count())\r\n",
        "tn = float(predicted.filter(\"prediction == 0.0 AND truelabel == 0\").count())\r\n",
        "fn = float(predicted.filter(\"prediction == 0.0 AND truelabel == 1\").count())\r\n",
        "metrics = spark.createDataFrame([\r\n",
        " (\"TP\", tp),\r\n",
        " (\"FP\", fp),\r\n",
        " (\"TN\", tn),\r\n",
        " (\"FN\", fn),\r\n",
        " (\"Precision\", tp / (tp + fp)),\r\n",
        " (\"Recall\", tp / (tp + fn))],[\"metric\", \"value\"])\r\n",
        "display(metrics)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## View the Raw Prediction and Probability\r\n",
        "The prediction is based on a raw prediction score that describes a labelled point in a logistic function. This raw prediction is then converted to a predicted label of 0 or 1 based on a probability vector that indicates the confidence for each possible label value (in this case, 0 and 1). The value with the highest confidence is selected as the prediction."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prediction.select(\"rawPrediction\", \"probability\", col(\"prediction\").cast(\"int\"), col(\"Late\").alias(\"trueLabel\")).show(100, truncate=False)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that the results include rows where the probability for 0 (the first value in the **probability** vector) is only slightly higher than the probability for 1 (the second value in the **probability** vector). The default *discrimination threshold* (the boundary that decides whether a probability is predicted as a 1 or a 0) is set to 0.5; so the prediction with the highest probability is always used, no matter how close to the threshold.\r\n",
        "\r\n",
        "### Review the Area Under ROC\r\n",
        "Another way to assess the performance of a classification model is to measure the area under a *received operator characteristic (ROC) curve* for the model. Spark MLlib includes a **BinaryClassificationEvaluator** class that you can use to compute this. A ROC curve plots the True Positive and False Positive rates for varying threshold values (the probability value over which a positive label is predicted). The area under this curve gives an overall indication of the model's predictive performance as a value between 0 and 1. A value under 0.5 means that a binary classification model (which predicts one of two possible labels) is no better at predicting the right class than a random 50/50 guess."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\r\n",
        "\r\n",
        "# Plot the ROC curve\r\n",
        "modelSummary = model.stages[-1].summary\r\n",
        "plt.plot([0, 1], [0, 1], 'r--')\r\n",
        "plt.plot(modelSummary.roc.select('FPR').collect(),\r\n",
        "         modelSummary.roc.select('TPR').collect())\r\n",
        "plt.xlabel('False Positive Rate')\r\n",
        "plt.ylabel('True Positive Rate')\r\n",
        "plt.show()\r\n",
        "\r\n",
        "# Get the AUC\r\n",
        "evaluator = BinaryClassificationEvaluator(labelCol=\"Late\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\r\n",
        "auc = evaluator.evaluate(prediction)\r\n",
        "print (\"AUC = \", auc)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from onnxmltools import convert_sparkml\r\n",
        "from onnxconverter_common.data_types import *\r\n",
        "\r\n",
        "initial_types = [('DayofMonth', StringTensorType(shape=[1, 1])),\r\n",
        "                 ('DayOfWeek', StringTensorType(shape=[1, 1])),\r\n",
        "                 ('Carrier', StringTensorType(shape=[1, 1])),\r\n",
        "                 ('OriginAirportID', StringTensorType(shape=[1, 1])),\r\n",
        "                 ('DestAirportID', StringTensorType(shape=[1, 1])),\r\n",
        "                 ('DepDelay', FloatTensorType(shape=[1, 1]))]\r\n",
        "onnx_model = convert_sparkml(model, 'Pyspark model', initial_types, target_opset = 7)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(onnx_model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\r\n",
        "\r\n",
        "modelpath = filestore + \"/flight_model4/\"\r\n",
        "mlflow.onnx.save_model(onnx_model, modelpath)\r\n",
        "print(\"Model saved to \", modelpath)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, pandas_udf,udf,lit\r\n",
        "import azure.synapse.ml.predict as pcontext\r\n",
        "from mlflow.utils import model_utils\r\n",
        "import azure.synapse.ml.predict.utils._logger as synapse_predict_logger\r\n",
        "\r\n",
        "#Enable SynapseML predict\r\n",
        "spark.conf.set(\"spark.synapse.ml.predict.enabled\",\"true\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Set input data path\r\n",
        "DATA_FILE = \"/data/new-flights.csv\"\r\n",
        "\r\n",
        "#Set ADLS URI, if trained model is uploaded in ADLS\r\n",
        "MODEL_URI = modelpath\r\n",
        "\r\n",
        "#Define model return type\r\n",
        "RETURN_TYPES = \"int\" # for ex: int, float etc. PySpark data types are supported\r\n",
        "\r\n",
        "#Define model runtime. This supports only mlflow\r\n",
        "RUNTIME = \"mlflow\"\r\n",
        "\r\n",
        "#Bind model within Spark session\r\n",
        "mlflow_model = pcontext.bind_model(\r\n",
        "    return_types=RETURN_TYPES, \r\n",
        "    runtime=RUNTIME, \r\n",
        "    model_alias=\"flight_model\", #This alias will be used in PREDICT call to refer  this   model\r\n",
        "    model_uri=MODEL_URI #In case of AML, it will be AML_MODEL_URI\r\n",
        "    ).register()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Read data from ADLS\r\n",
        "df = spark.read \\\r\n",
        ".format(\"csv\") \\\r\n",
        ".option(\"header\", \"true\") \\\r\n",
        ".csv(DATA_FILE,\r\n",
        "    inferSchema=True)\r\n",
        "df.createOrReplaceTempView('new_flights')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Call PREDICT using Spark SQL API\r\n",
        "\r\n",
        "predictions = spark.sql(\r\n",
        "                \"\"\"\r\n",
        "                    SELECT PREDICT(\"delay_model\", DayofMonth, DayOfWeek, CarrierIdx, OriginAirportID, DestAirportID, DepDelay) AS predict \r\n",
        "                    FROM new_flights\r\n",
        "                \"\"\"\r\n",
        "            ).show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Call PREDICT using user defined function (UDF)\r\n",
        "\r\n",
        "df = df[\"DayofMonth\", \"DayOfWeek\", \"Carrier\", \"OriginAirportID\", \"DestAirportID\", \"DepDelay\"] # for ex. df[\"empid\",\"empname\"]\r\n",
        "\r\n",
        "df.withColumn(\"PREDICT\",mlflow_model.udf(lit(\"late\"),*df.columns)).show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Call PREDICT using Transformer API\r\n",
        "\r\n",
        "columns = [\"DayofMonth\", \"DayOfWeek\", \"Carrier\", \"OriginAirportID\", \"DestAirportID\", \"DepDelay\"] # for ex. df[\"empid\",\"empname\"]\r\n",
        "\r\n",
        "tranformer = mlflow_model.create_transformer().setInputCols(columns).setOutputCol(\"PREDICT\")\r\n",
        "\r\n",
        "tranformer.transform(df).show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "type(mlflow_model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "language": "Python",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "description": null,
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}